
     "text": [
      "prompt :topics to teach in AI.output in  dictionary\n",
      "output from LLM:ChatCompletion(id='chatcmpl-CdCYFljDBxHjIRe1CDztolUVHbGNo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n    \"1. Introduction to AI\": [\"Definition of AI\", \"History of AI\", \"Types of AI (Narrow, General, Superintelligence)\"],\\n    \"2. Machine Learning\": [\"Supervised Learning\", \"Unsupervised Learning\", \"Reinforcement Learning\", \"Key Algorithms (e.g., Linear Regression, Decision Trees, Neural Networks)\"],\\n    \"3. Deep Learning\": [\"Neural Networks Basics\", \"Convolutional Neural Networks (CNNs)\", \"Recurrent Neural Networks (RNNs)\", \"Transformers and Attention Mechanisms\"],\\n    \"4. Natural Language Processing\": [\"Text Preprocessing\", \"Sentiment Analysis\", \"Chatbots\", \"Language Models (e.g., GPT, BERT)\"],\\n    \"5. Computer Vision\": [\"Image Processing Basics\", \"Object Detection\", \"Image Classification\", \"Face Recognition\"],\\n    \"6. AI Ethics and Responsible AI\": [\"Bias in AI\", \"Privacy Concerns\", \"Explainability and Transparency\", \"AI Governance\"],\\n    \"7. Robotics and AI Applications\": [\"AI in Robotics\", \"Autonomous Vehicles\", \"Healthcare AI Applications\", \"AI in Finance\"],\\n    \"8. Reinforcement Learning\": [\"Markov Decision Processes\", \"Monte Carlo Methods\", \"Q-Learning\", \"Applications in Gaming\"],\\n    \"9. Big Data and AI\": [\"Data Preprocessing\", \"Data Warehousing\", \"Role of Big Data in AI\"],\\n    \"10. AI Tools and Frameworks\": [\"TensorFlow\", \"PyTorch\", \"Scikit-learn\", \"Keras\"],\\n    \"11. Production and Deployment\": [\"AI Model Deployment\", \"Monitoring Performance\", \"Scaling AI Applications\"],\\n    \"12. Trends in AI\": [\"Generative AI\", \"Edge AI\", \"AI and Quantum Computing\"]\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1763459075, model='gpt-4o-2024-11-20', object='chat.completion', service_tier=None, system_fingerprint='fp_b54fe76834', usage=CompletionUsage(completion_tokens=365, prompt_tokens=31, total_tokens=396, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "#pip install llm-azure\n",
    "#reference\n",
    "#https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/responses?tabs=python-key\n",
    "#https://learn.microsoft.com/en-us/azure/ai-foundry/openai/references/on-your-data?tabs=python\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()# which loads AZURE_OPENAI_API_KEY api key  from the environment\n",
    "from llm_azure import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(azure_endpoint=\"\",\n",
    "    azure_deployment=\"\",\n",
    "    api_version=\"\")\n",
    "\n",
    "prompt=\"topics to teach in AI.output in  dictionary\"\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.give me the output alone\"}, # role/persona\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt  #prompt->task by the user\n",
    "            \n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(f'prompt :{prompt}')\n",
    "print(f'output from LLM:{completion}')\n",
    "# print(completion.usage.total_tokens)\n",
    "# print(completion.usage.total_tokens)\n",
    "# print(completion.usage.prompt_tokens)\n",
    "# print(completion.usage.completion_tokens)\n",
    "# print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0711fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1. Introduction to AI\": [\"Definition of AI\", \"History of AI\", \"Types of AI (Narrow, General, Superintelligence)\"],\n",
      "    \"2. Machine Learning\": [\"Supervised Learning\", \"Unsupervised Learning\", \"Reinforcement Learning\", \"Key Algorithms (e.g., Linear Regression, Decision Trees, Neural Networks)\"],\n",
      "    \"3. Deep Learning\": [\"Neural Networks Basics\", \"Convolutional Neural Networks (CNNs)\", \"Recurrent Neural Networks (RNNs)\", \"Transformers and Attention Mechanisms\"],\n",
      "    \"4. Natural Language Processing\": [\"Text Preprocessing\", \"Sentiment Analysis\", \"Chatbots\", \"Language Models (e.g., GPT, BERT)\"],\n",
      "    \"5. Computer Vision\": [\"Image Processing Basics\", \"Object Detection\", \"Image Classification\", \"Face Recognition\"],\n",
      "    \"6. AI Ethics and Responsible AI\": [\"Bias in AI\", \"Privacy Concerns\", \"Explainability and Transparency\", \"AI Governance\"],\n",
      "    \"7. Robotics and AI Applications\": [\"AI in Robotics\", \"Autonomous Vehicles\", \"Healthcare AI Applications\", \"AI in Finance\"],\n",
      "    \"8. Reinforcement Learning\": [\"Markov Decision Processes\", \"Monte Carlo Methods\", \"Q-Learning\", \"Applications in Gaming\"],\n",
      "    \"9. Big Data and AI\": [\"Data Preprocessing\", \"Data Warehousing\", \"Role of Big Data in AI\"],\n",
      "    \"10. AI Tools and Frameworks\": [\"TensorFlow\", \"PyTorch\", \"Scikit-learn\", \"Keras\"],\n",
      "    \"11. Production and Deployment\": [\"AI Model Deployment\", \"Monitoring Performance\", \"Scaling AI Applications\"],\n",
      "    \"12. Trends in AI\": [\"Generative AI\", \"Edge AI\", \"AI and Quantum Computing\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9db055fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "# from xai_grok import Grok\n",
    "# from xai_grok.schemas import ChatRequest\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# # Initialize client\n",
    "# client = Grok(api_key=os.getenv(\"XAI_API_KEY\"))\n",
    "\n",
    "# # Prepare messages\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Whatâ€™s the square of 25?\"}\n",
    "# ]\n",
    "\n",
    "# # Call Grok\n",
    "# response = client.chat_completions(\n",
    "#     ChatRequest(messages=messages, model=\"grok-beta\")\n",
    "# )\n",
    "\n",
    "# # Print response\n",
    "# print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c384a606",
   "metadata": {},
   "source": [
    "Langchain framework\n",
    "chat models unify different apis\n",
    "Easy switching between llms\n",
    "Context management\n",
    "Efficient Chaining\n",
    "Scalability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794eefe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am running on OpenAI's GPT-4 model, which has been integrated with LangChain to enhance its capabilities, such as chaining prompts, retrieval-augmented generation (RAG), and other advanced NLP workflows. If you're leveraging Azure for this, it's possible that you're interfacing with OpenAI's GPT models through Azure OpenAI Service. Is that correct?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=\"\",\n",
    "    azure_deployment=\"\",\n",
    "    api_version=\"\",\n",
    "    model='',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Hello from LangChain + Azure!which model are you running\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb2e2140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello! I am running on OpenAI's GPT-4 model, which has been integrated with LangChain to enhance its capabilities, such as chaining prompts, retrieval-augmented generation (RAG), and other advanced NLP workflows. If you're leveraging Azure for this, it's possible that you're interfacing with OpenAI's GPT models through Azure OpenAI Service. Is that correct?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 19, 'total_tokens': 95, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-CdCdeTGv9djFmPmskGsRKvaEvwojl', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--0cb9e4f2-52d7-46c5-98a7-9448d039b0b3-0' usage_metadata={'input_tokens': 19, 'output_tokens': 76, 'total_tokens': 95, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df86d6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.system.SystemMessage'>\n",
      "You are a senior software engineer in data analytics company\n",
      "- **Ethical AI and Responsible Machine Learning**: Dive deep into the importance of fairness, accountability, transparency, and bias mitigation in AI systems. Discuss real-world scenarios where ethical considerations play a major role and explore techniques to build trustworthy AI solutions.\n",
      "\n",
      "- **Generative AI in Action: Transforming Creativity and Industries**: Explore the advancements in generative AI, such as GPT models, DALL-E, and others, showcasing their applications in media, marketing, content creation, and beyond. Highlight innovative use cases and discuss the future impact of generative AI across industries.\n",
      "content='- **Ethical AI and Responsible Machine Learning**: Dive deep into the importance of fairness, accountability, transparency, and bias mitigation in AI systems. Discuss real-world scenarios where ethical considerations play a major role and explore techniques to build trustworthy AI solutions.\\n\\n- **Generative AI in Action: Transforming Creativity and Industries**: Explore the advancements in generative AI, such as GPT models, DALL-E, and others, showcasing their applications in media, marketing, content creation, and beyond. Highlight innovative use cases and discuss the future impact of generative AI across industries.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 34, 'total_tokens': 150, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-CdCfmZh7Iogpe88NgIWZX3hNCKCFv', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--1fa36200-d517-4d3b-adb5-25769dc2abc4-0' usage_metadata={'input_tokens': 34, 'output_tokens': 116, 'total_tokens': 150, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,SystemMessage,HumanMessage\n",
    "#SystemMessage->AI role and sets the context\n",
    "#HumanMessage->represent user input or questions directed to the AI\n",
    "#AIMessage->contains AI's response of previous message\n",
    "\n",
    "message=[SystemMessage('You are a senior software engineer in data analytics company'),\n",
    "         HumanMessage('Give 2 engaging AI topics to take session on as bullet points')]\n",
    "\n",
    "print(type(message))\n",
    "print(type(message[0]))\n",
    "print(message[0].content)\n",
    "response = llm.invoke(message)\n",
    "print(response.content)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
